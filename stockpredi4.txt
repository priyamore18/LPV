# -*- coding: utf-8 -*-
"""DL4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W-QlSEspEXykXoiN01zUwc4xKg9Sdgaq

# Assignment No.04

# Title of the Assignment: Recurrent Neural Network (RNN) for Time Series Prediction

## Objective:
- Implement a **Recurrent Neural Network (RNN)** using historical stock price data.
- Use the **Google Stock Price** dataset for time series forecasting.
- Understand the concepts behind RNNs and how they are applied in time series prediction.
"""

# Step 1: Suppress Warnings and Import Required Libraries
import warnings
warnings.filterwarnings('ignore')

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense

# Step 2: Load Dataset
# Assuming you've downloaded 'GOOG.csv' from Yahoo Finance or Kaggle
# Make sure to place it in the same folder or provide full path
df = pd.read_csv("GOOGL.csv")  # Google stock price dataset
df.head()

# Step 3: Data Preprocessing
# We'll use 'Close' price for prediction
df = df[['Date', 'Close']]
df['Date'] = pd.to_datetime(df['Date'])
df.set_index('Date', inplace=True)

# Visualize
df['Close'].plot(title="Google Stock Closing Price", figsize=(10, 5))
plt.grid(True)
plt.show()

# Step 4: Prepare Time Series Data
data = df['Close'].values.reshape(-1, 1)

# Normalize the data
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data)

# Create sequences
def create_sequences(data, seq_length=60):
    x, y = [], []
    for i in range(seq_length, len(data)):
        x.append(data[i - seq_length:i])
        y.append(data[i])
    return np.array(x), np.array(y)

sequence_length = 60
x, y = create_sequences(data_scaled, sequence_length)

# Train-test split (80-20)
split = int(0.8 * len(x))
x_train, x_test = x[:split], x[split:]
y_train, y_test = y[:split], y[split:]

print("Training shape:", x_train.shape, y_train.shape)
print("Testing shape:", x_test.shape, y_test.shape)

"""Let’s say i = 63 and sequence_length = 60:

x[3] = data[3:63] → this is a list of 60 values (data[3] to data[62])

y[3] = data[63] → the 61st value (to be predicted)
"""

# Step 5: Build the RNN Model
model = Sequential([
    SimpleRNN(50, activation='tanh', input_shape=(x_train.shape[1], 1)),
    Dense(1)
])

model.compile(optimizer='adam', loss='mean_squared_error')
model.summary()

"""the tanh activation function (short for hyperbolic tangent) is a common nonlinear activation function used in neural networks, especially in RNNs and LSTMs. If you give it:

A large positive number → it gives a result close to +1

A large negative number → it gives a result close to -1

Zero → it gives 0


"""

# Step 6: Train the Model
history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.1, verbose=1)

# Step 7: Model Evaluation
loss = model.evaluate(x_test, y_test)
print(f"\nTest Loss (MSE): {loss:.6f}")

# Step 8: Predictions and Plotting
predicted = model.predict(x_test)
predicted_prices = scaler.inverse_transform(predicted)
actual_prices = scaler.inverse_transform(y_test)

# Plot
plt.figure(figsize=(10, 5))
plt.plot(actual_prices, label="Actual Price")
plt.plot(predicted_prices, label="Predicted Price")
plt.title("Google Stock Price Prediction using RNN")
plt.xlabel("Time")
plt.ylabel("Stock Price")
plt.legend()
plt.grid(True)
plt.show()

"""scaler.inverse_transform is used to convert data back to its original form after it has been scaled or normalized."""

# Step 9: Predict Next Day's Stock Price
last_sequence = data_scaled[-sequence_length:]
next_input = last_sequence.reshape((1, sequence_length, 1))
next_pred = model.predict(next_input)
next_price = scaler.inverse_transform(next_pred)
print(f"Predicted next day's stock price: ${next_price[0][0]:.2f}")

"""Extract the last sequence_length data points (scaled stock prices).

Reshape them to the format the model expects for prediction.

Predict the next stock price using the model.

Convert the prediction back to the original scale (from scaled form to actual price).

Print the predicted stock price for the next day
"""

# Step 10: Predict Next 7 Days Stock Prices

future_predictions = []
input_seq = data_scaled[-sequence_length:]  # last 60 days

for _ in range(7):  # next 7 days
    pred = model.predict(input_seq.reshape(1, sequence_length, 1))
    future_predictions.append(pred[0][0])
    input_seq = np.append(input_seq, pred)[1:]  # slide window forward

# Inverse scale
future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))

# Print predicted values
for i, price in enumerate(future_predictions, 1):
    print(f"Day {i}: ${price[0]:.2f}")

"""Extract the last sequence_length days of data.

Predict the stock price for the next 7 days by using the model and sliding the input window forward.

Convert the predictions back to the original scale (e.g., actual stock price in dollars).

Print the predicted stock prices for the next 7 days
"""

# Extend the plot with future predictions
last_actual_day = df.index[-1]
future_dates = pd.date_range(last_actual_day + pd.Timedelta(days=1), periods=7)

plt.figure(figsize=(10, 5))
plt.plot(df.index[-100:], df['Close'].values[-100:], label="Actual Price (last 100 days)")
plt.plot(future_dates, future_predictions, 'r--o', label="Predicted Next 7 Days")
plt.title("Google Stock Price Forecast")
plt.xlabel("Date")
plt.ylabel("Stock Price")
plt.legend()
plt.grid(True)
plt.show()

"""the graph will show:

The actual stock prices for the last 100 days (using a solid line).

The predicted stock prices for the next 7 days (using a red dashed line with markers).

This helps visualize how the model forecasts future stock prices based on historical data.
"""

